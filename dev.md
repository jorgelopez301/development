# Stable Diffusion

ComfyUI, Automatic111, Fooocus
(Lora: Light weight for Stable Diffusion)

https://github.com/C0untFloyd/bark-gui

# Lip Syncing

Wav2lip(Rudrabha)
https://github.com/Rudrabha/Wav2Lip
https://colab.research.google.com/github/justinjohn0306/Wav2Lip/blob/master/Wav2Lip_simplified_v5.ipynb
SadTalker(OpenTalker)
https://github.com/OpenTalker/SadTalker

# Gooey AI (https://gooey.ai/)

GFPGAN(Tencent ARC), REAL-ESRGAN(xinntao), Stable Diffusion x4(xinntao),

# Various Neural Types

ImplicitNeuralNetwork (Continuous Neural Network)
UnsupervisedDomainAdaptation(UDA4POC) (For Image Segmentation, Calculating count of rice grains)

# Large Vision Language Model

AnomalyGPT, ParaEmbed 2.0
By integrating open-source models like BGE-base-v1.5, Llama 2 70B, Falcon 40B, and Mixtral 8x7B, and fine-tuning on proprietary patent data with guidance from Hugging Face, XLSCOUT achieved more tailored and performant solutions. This shift allowed for a more accurate understanding of intricate technical concepts and terminologies, revolutionizing the analysis and understanding of technical documents and patents.

# Large Language Model

OnPrem
https://github.com/amaiya/onprem
https://amaiya.github.io/onprem/
OnPrem.LLM is a simple Python package that makes it easier to run large language models (LLMs) on your own machines using non-public data (possibly behind corporate firewalls). Inspired largely by the privateGPT GitHub repo, OnPrem.LLM is intended to help integrate local LLMs into practical applications.

# Platforms

https://h2o.ai/
Open-Sora: Democratizing Efficient Video Production for All
(https://github.com/hpcaitech/Open-Sora, https://huggingface.co/hpcai-tech/Open-Sora)
https://aihub.or.kr/

# English-Conversation(KKR)

https://github.com/naver-ai/model-stock

https://www.upstage.ai/

https://github.com/teddysum/bllossom (Fine-tune from LLama2)

# Outfit Anyone

https://humanaigc.github.io/outfit-anyone/
https://github.com/selfitcamera/Outfit-Anyone-in-the-Wild?tab=readme-ov-file
https://github.com/fyviezhao/M3D-VTON
https://github.com/xiezhy6/GP-VTON
https://github.com/HumanAIGC/OutfitAnyone
https://github.com/InstantID/InstantID
https://github.com/cuiaiyu/street-tryon-benchmark
https://github.com/microsoft/MeshGraphormer
https://github.com/modelscope/modelscope

Manim
https://github.com/manimCommunity/manim?tab=readme-ov-file
https://huggingface.co/docs/transformers/en/model_doc/cohere

# 1.1 FER (Facial Emotion Recognition)

MediaPipe is a framework developed by Google for building multimodal (audio, video, time series, etc.) applied machine learning pipelines. It offers customizable ML solutions for live and streaming media, and is particularly well-known for its capabilities in facial recognition, hand tracking, and pose estimation.

https://github.com/ggerganov/llama.cpp

https://github.com/Emerging-AI/ENOVA
https://www.emergingai.pro

https://github.com/jupyterlab/jupyter-ai

https://neptune.ai/

https://paperswithcode.com/paper/attention-is-all-you-need

Kaggle Dataset

Bioinformatics

LayoutML
https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM

A hot topic and development in the realm artificial intelligence (AI) is Large Action Models, also referred as Large Agentic Models or LAMs in short.

neuro-symbolic programming

implement it, pdf here
https://arxiv.org/pdf/2301.12662v1
article
https://www.deeplearning.ai/the-batch/singsong-a-tool-that-generates-instrumental-music-for-unaccompanied-input-vocals/
working demo
https://storage.googleapis.com/sing-song/index.html

https://github.com/ollama/ollama/
https://github.com/open-webui/open-webui
https://github.com/oobabooga/text-generation-webui

https://github.com/confident-ai/deepeval

https://llama.meta.com/llama-downloads/
https://github.com/meta-llama/llama
https://github.com/meta-llama/llama-models
https://github.com/liltom-eth/llama2-webui

https://github.com/openai/openai-cookbook
https://github.com/lm-sys/FastChat
https://tiktokenizer.vercel.app/

https://github.com/openai/evals

https://github.com/d2l-ai/d2l-en

https://github.com/openai/tiktoken

https://chat.lmsys.org/

Pydantic

AudioLM

https://www.deepspeed.ai/training/, https://github.com/microsoft/DeepSpeed
Training advanced deep learning models is challenging. Beyond model design, model scientists also need to set up the state-of-the-art training techniques such as distributed training, mixed precision, gradient accumulation, and checkpointing. Yet still, scientists may not achieve the desired system performance and convergence rate. Large model sizes are even more challenging: a large model easily runs out of memory with pure data parallelism and it is difficult to use model parallelism. DeepSpeed addresses these challenges to accelerate model development and training.

https://github.com/karpathy/llm.c
https://github.com/tamangmilan/llm_from_scratch
https://github.com/karpathy/char-rnn/blob/master/data/tinyshakespeare/input.txt
